# Stock Tracker

A self-updating stock dashboard that tracks all companies with a market cap > $2B.
Data is sourced from [Finviz](https://finviz.com) and the page updates automatically
every **Sunday at 8 PM Eastern** via GitHub Actions.

## Features

- **Covers all tickers** with market cap > $2B from the Finviz screener
- **Cap category badges**: Mid Cap ($2B–$20B), Large Cap ($20B–$200B), Mega Cap ($200B+)
- **Click any column header to sort** (ascending/descending, numeric-aware)
- **Filter by cap category** or search by ticker symbol
- **Columns**: Ticker, Market Cap, Category, Next Earnings Date, EPS Y/Y TTM, Sales Y/Y TTM,
  EPS/Sales Surprise, EPS & Revenue Quarterly YoY (Est. & Rep.), Revenue Annual (Est. & Rep.),
  EPS & Sales Up/Down Revisions, Avg Target Price

---

## Setup (5 minutes)

### 1. Create a GitHub repository

```bash
git init
git remote add origin https://github.com/YOUR_USERNAME/YOUR_REPO_NAME.git
```

Add these files to the repo:
```
stock-tracker/
├── scraper.py
├── index.html          ← generated by scraper; commit a blank one initially
├── .github/
│   └── workflows/
│       └── update.yml
└── README.md
```

### 2. Create an initial `index.html`

Run the scraper locally once to generate the first version:

```bash
pip install requests beautifulsoup4 lxml
python scraper.py
```

Then commit and push everything:

```bash
git add .
git commit -m "Initial commit"
git push -u origin main
```

### 3. Enable GitHub Pages

1. Go to your repo on GitHub → **Settings** → **Pages**
2. Under **Source**, select **Deploy from a branch**
3. Choose branch: `main`, folder: `/ (root)`
4. Click **Save**

Your page will be live at:
```
https://YOUR_USERNAME.github.io/YOUR_REPO_NAME/
```

### 4. Verify the workflow

- Go to **Actions** tab in your repo
- You should see the `Update Stock Tracker` workflow
- Click **Run workflow** to trigger it manually and confirm it works

---

## Timezone Note

The cron job is set for **Sunday 8 PM EDT (UTC-4)** = Monday 00:00 UTC.
During winter (EST, UTC-5), 8 PM ET = Monday 01:00 UTC.

To handle EST automatically, you can use two cron entries in `update.yml` or just
accept a 1-hour drift in winter. Edit the cron in `.github/workflows/update.yml`
to switch between the two.

---

## Important Notes

- **Rate limiting**: The scraper adds polite delays between requests. With thousands
  of tickers, a full scrape may take 30–60 minutes. GitHub Actions allows up to 6 hours
  per job, so this is fine.
- **Finviz ToS**: This scraper is for personal/non-commercial use only.
- **Data accuracy**: Some Finviz fields may be mapped differently depending on the
  view. Check `scraper.py`'s `build_stock_record()` function and adjust field names
  if any columns appear blank after reviewing the raw data.

---

## Customization

- **Add/remove tickers**: The screener URL in `scraper.py` uses `f=cap_midover`
  (all caps > $2B). You can modify this to any Finviz screener filter set.
- **Add columns**: Add new keys in `build_stock_record()`, a new `<th>` in the
  HTML template, and a new `cell()` call in the JS `renderTable()` function.
- **Change update frequency**: Edit the `cron` expression in `update.yml`.
